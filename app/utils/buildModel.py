# backend/build_model.py

import os
import pandas as pd
import numpy as np
from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors
import joblib
from datetime import datetime

def log(msg):
    print(f"[{datetime.now():%H:%M:%S}] {msg}")

# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ART_DIR = os.path.join(os.path.dirname(__file__), "artifacts")
os.makedirs(ART_DIR, exist_ok=True)

# â”€â”€â”€ 1) Load CSVs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("ðŸ“¥ Loading CSVsâ€¦")
ratings = pd.read_csv("../../dataset/Ratings.csv", usecols=["User-ID","ISBN","Book-Rating"])
books   = pd.read_csv("../../dataset/Books.csv",   usecols=["ISBN","Book-Title"])
ratings.columns = ["user_id","ISBN","rating"]
books  .columns = ["ISBN","title"]
log(f"âœ… Ratings: {len(ratings):,} rows; Books: {len(books):,} rows")

# â”€â”€â”€ 2) Merge to get titles in ratings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("ðŸ”— Merging ratings with titlesâ€¦")
df = ratings.merge(books, on="ISBN", how="inner")
log(f"âœ… Merged: {len(df):,} rows")

# â”€â”€â”€ 3) Create mappings to integer indices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("ðŸ”¢ Generating title & user indicesâ€¦")
titles = df["title"].unique().tolist()
users  = df["user_id"].unique().tolist()
title_to_idx = {t:i for i,t in enumerate(titles)}
user_to_idx  = {u:i for i,u in enumerate(users)}
n_titles = len(titles)
n_users  = len(users)
log(f"âœ… {n_titles:,} unique titles; {n_users:,} unique users")

# â”€â”€â”€ 4) Build sparse rating matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("ðŸ§© Building sparse rating matrixâ€¦")
rows = df["title"].map(title_to_idx).to_numpy()
cols = df["user_id"].map(user_to_idx).to_numpy()
data = df["rating"].to_numpy()
sparse_mat = csr_matrix((data, (rows, cols)), shape=(n_titles, n_users))
log(f"âœ… Sparse matrix shape: {sparse_mat.shape}, nnz={sparse_mat.nnz:,}")

# â”€â”€â”€ 5) Train NearestNeighbors â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("ðŸ¤– Training NearestNeighbors (item-CF)â€¦")
model = NearestNeighbors(metric="minkowski", p=2, algorithm="brute")
model.fit(sparse_mat)
log("âœ… Model trained")

# â”€â”€â”€ 6) Build ISBN map â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
isbn_map = dict(zip(books["title"], books["ISBN"]))

# â”€â”€â”€ 7) Dump artifacts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("ðŸ’¾ Dumping artifactsâ€¦")
joblib.dump(model,      os.path.join(ART_DIR, "model_ib.pkl"))
joblib.dump(titles,     os.path.join(ART_DIR, "titles.pkl"))
joblib.dump(isbn_map,   os.path.join(ART_DIR, "isbn_map.pkl"))
joblib.dump(user_to_idx,os.path.join(ART_DIR, "user_to_idx.pkl"))
joblib.dump(title_to_idx,os.path.join(ART_DIR, "title_to_idx.pkl"))
log("âœ… All artifacts saved to ./artifacts/")
